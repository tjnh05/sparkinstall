---
# Create sparkuser home directory of hdfs
# written by bodhi wang
# jyxz5@qq.com
# Dec 26, 2017
- hosts: sparkm.xxx.com
  become: yes
  become_user: root

  vars:
     SPARK_HOME: /usr/hdp/current/spark2-client/
     SPARK_PY_NOTEBOOKS: /opt/data/spark-py-notebooks/
     LEARNING_PYSPARK: /home/sparkuser/Learning-PySpark/
     SPARK_MAJOR_VERSION: 2
     GIT_DIR: /usr/local/src/
     PROXY_SERV: 10.13.1.94

  tasks:
   - name: Set environment variable SPARK_MAJOR_VERSION as 2
     lineinfile:
       path: /etc/environment
       regexp: '^export SPARK_MAJOR_VERSION'
       line: 'export SPARK_MAJOR_VERSION=2'

   - name: Check if HDFS directory /user/sparkuser exists
     shell: "sudo -u hdfs hadoop fs -test -d /user/sparkuser; echo $?"
     register: retval
     args:
       warn: no
     changed_when: false
     
   - debug: var=retval

   - name: Create HDFS home directory for user sparkuser
     command: "sudo -u hdfs hadoop fs -mkdir -p /user/sparkuser"
     when: retval.stdout == "1"
     args:
       warn: no
     
   - name: Change owner of HDFS directory /user/sparkuser to sparkuser
     command: "sudo -u hdfs hadoop fs -chown sparkuser /user/sparkuser"
     args:
       warn: no

   - name: Create directory downloads
     file:
       path: /root/downloads
       state: directory
       recurse: yes
       owner: root
       group: root
       mode:  0755

   - name: Create symbolic link from source /opt/data/spark-py-notebooks
     command: "ln -s /opt/data/spark-py-notebooks {{SPARK_HOME}}spark-py-notebooks"
     args:
       creates: "{{SPARK_HOME}}spark-py-notebooks" 
       
   - name: Download file VS14MORT.txt.gz if not exists
     get_url:
       dest: /home/sparkuser/VS14MORT.txt.gz
       url: http://tomdrabas.com/data/VS14MORT.txt.gz

   - name: Check if HDFS file /user/sparkuser/VS14MORT.txt.gz exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/VS14MORT.txt.gz
     register: retval
     args:
       warn: no
     changed_when: false
   - debug: var=retval
     
   - name: Put VS14MORT.txt.gz
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - /home/sparkuser/VS14MORT.txt.gz
     when: retval.results[0].stdout == "1"
     args:
       warn: no
     
   - name: Check if HDFS directory /user/sparkuser/data exists
     shell: "sudo -u sparkuser hadoop fs -test -d {{item}}; echo $?"
     with_items:
       - /user/sparkuser/data
     register: retval
     args:
       warn: no
     changed_when: false
   - debug: var=retval
     
   - name: Put /user/sparkuser/data
     command: "sudo -u sparkuser hadoop fs -put {{item}} data"
     with_items:
       - "{{SPARK_HOME}}data/"
     when: retval.results[0].stdout == "1"
     args:
       warn: no
     
   - name: Check if HDFS file /user/sparkuser/README.md exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/README.md
     register: retval
     args:
       warn: no
     changed_when: false
   - debug: var=retval
     
   - name: Put /user/sparkuser/README.md
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "{{SPARK_PY_NOTEBOOKS}}README.md"
     when: retval.results[0].stdout == "1"
     args:
       warn: no
     
   - name: Check if HDFS file /user/sparkuser/kddcup.data_10_percent.gz exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/kddcup.data_10_percent.gz
     register: retval
     args:
       warn: no
     changed_when: false
   - debug: var=retval
     
   - name: Put /user/sparkuser/kddcup.data_10_percent.gz
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "{{SPARK_PY_NOTEBOOKS}}nb10-sql-dataframes/kddcup.data_10_percent.gz"
     when: retval.results[0].stdout == "1"
     args:
       warn: no
     
   - name: Check if HDFS file /user/sparkuser/kddcup.data.gz exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/kddcup.data.gz
     register: retval
     args:
       warn: no
     changed_when: false
   - debug: var=retval
     
   - name: Put /user/sparkuser/kddcup.data.gz
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "{{SPARK_PY_NOTEBOOKS}}nb3-rdd-sampling/kddcup.data.gz"
     when: retval.results[0].stdout == "1"
     args:
       warn: no
     
   - name: Check if HDFS file /user/sparkuser/corrected.gz exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/corrected.gz
     register: retval
     args:
       warn: no
     changed_when: false
     
   - name: Put /user/sparkuser/corrected.gz
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "{{SPARK_PY_NOTEBOOKS}}nb8-mllib-logit/corrected.gz"
     when: retval.results[0].stdout == "1"
     args:
       warn: no
       
   - name: Check if HDFS file /user/sparkuser/flight-data exists
     shell: "sudo -u sparkuser hadoop fs -test -d {{item}}; echo $?"
     with_items:
       - /user/sparkuser/flight-data
     register: retval
     args:
       warn: no
     changed_when: false
     
   - name: Put /user/sparkuser/flight-data
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "{{LEARNING_PYSPARK}}Chapter02/flight-data"
     when: retval.results[0].stdout == "1"
     args:
       warn: no

   - name: Check if HDFS file /user/sparkuser/ccFraud.csv.gz exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/ccFraud.csv.gz
     register: retval
     args:
       warn: no
     changed_when: false
     
   - name: Put /user/sparkuser/ccFraud.csv.gz
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "/home/sparkuser/ccFraud.csv.gz"
     when: retval.results[0].stdout == "1"
     args:
       warn: no

   - name: Check if HDFS file /user/sparkuser/births_train.csv.gz exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/births_train.csv.gz
     register: retval
     args:
       warn: no
     changed_when: false
     
   - name: Put /user/sparkuser/births_train.csv.gz
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "/home/sparkuser/births_train.csv.gz"
     when: retval.results[0].stdout == "1"
     args:
       warn: no  

   - name: Check if HDFS file /user/sparkuser/births_transformed.csv.gz exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/births_transformed.csv.gz
     register: retval
     args:
       warn: no
     changed_when: false
     
   - name: Put /user/sparkuser/births_transformed.csv.gz
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "/home/sparkuser/births_transformed.csv.gz"
     when: retval.results[0].stdout == "1"
     args:
       warn: no 
 
   - name: Check if HDFS file /user/sparkuser/airports.dat exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/airports.dat
     register: retval
     args:
       warn: no
     changed_when: false
     
   - name: Put /user/sparkuser/airports.dat
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "/home/sparkuser/airports.dat"
     when: retval.results[0].stdout == "1"
     args:
       warn: no 
 
   - name: Check if HDFS file /user/sparkuser/airports-extended.dat exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/airports-extended.dat
     register: retval
     args:
       warn: no
     changed_when: false
     
   - name: Put /user/sparkuser/airports-extended.dat
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "/home/sparkuser/airports-extended.dat"
     when: retval.results[0].stdout == "1"
     args:
       warn: no 
 
   - name: Check if HDFS file /user/sparkuser/TrafficViolations.csv exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/TrafficViolations.csv
     register: retval
     args:
       warn: no
     changed_when: false
     
   - name: Put /user/sparkuser/TrafficViolations.csv
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "/home/sparkuser/TrafficViolations.csv"
     when: retval.results[0].stdout == "1"
     args:
       warn: no 
 
   - name: Check if HDFS file /user/sparkuser/TrafficViolations.csv.gz exists
     shell: "sudo -u sparkuser hadoop fs -test -f {{item}}; echo $?"
     with_items:
       - /user/sparkuser/TrafficViolations.csv.gz
     register: retval
     args:
       warn: no
     changed_when: false
     
   - name: Put /user/sparkuser/TrafficViolations.csv.gz
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "/home/sparkuser/TrafficViolations.csv.gz"
     when: retval.results[0].stdout == "1"
     args:
       warn: no 
 
   - name: Check if HDFS directory /user/sparkuser/uber_data_nyc_2016-06_3m_partitioned.csv exists
     shell: "sudo -u sparkuser hadoop fs -test -d {{item}}; echo $?"
     with_items:
       - /user/sparkuser/uber_data_nyc_2016-06_3m_partitioned.csv
     register: retval
     args:
       warn: no
     changed_when: false
   - debug: var=retval
     
   - name: Put /user/sparkuser/uber_data_nyc_2016-06_3m_partitioned.csv
     command: "sudo -u sparkuser hadoop fs -put {{item}}"
     with_items:
       - "/home/sparkuser/uber_data_nyc_2016-06_3m_partitioned.csv"
     when: retval.results[0].stdout == "1"
     args:
       warn: no

   - name: Install python modules
     #pip: name={{item}} state=present extra_args="--upgrade"
     pip: name={{item}} state=present
     with_items:
       - bokeh
       - tensorflow
       - blaze
       - sqlalchemy
       - pymongo
       - psycopg2
       - pygraphviz
       - xlrd
       - pandas
       - scikit-learn
       - tables
       - openpyxl
       - pytube
       - pathlib
       - ipywidgets

   - name: Install packages
     yum: name={{item}} state=present 
     with_items:
       - tkinter
       - python34-tkinter
       - graphviz
       - graphviz-devel

   - name: Enable widgetsnbextension for root user
     command: "jupyter nbextension enable --py widgetsnbextension"
     #args:
     #  warn: no

   - name: Enable widgetsnbextension for sparkuser user
     command: "sudo -u sparkuser jupyter nbextension enable --py widgetsnbextension"
     args:
       warn: no

   - name: Clone projects from remote repositories.
     git:
       repo: "{{item.repo}}"
       dest: "{{item.dest}}"
     with_items:
       - { repo: "https://github.com/rofl0r/proxychains-ng.git",dest: "{{GIT_DIR}}proxychains-ng" }

   - name: Install proxychains.
     shell: |
       ./configure && make && make install
       cat src/proxychains.conf| \
           sed -e 's/^socks4.*$/socks5 {{PROXY_SERV}} 1080/' \
               -e 's/^#quiet_mode.*$/quiet_mode/' \
               > /etc/proxychains.conf
     args:
       chdir: "{{GIT_DIR}}proxychains-ng"
       executable: /bin/sh
       creates: "/etc/proxychains.conf" 
      
   - name: Set environment variable PATH, append /usr/local/bin
     lineinfile:
       path: /etc/profile
       regexp: '^export PATH=\$PATH:/usr/local/bin$'
       state: absent
   - name: Set environment variable PATH, append /usr/local/bin
     lineinfile:
       path: /etc/profile
       regexp: '^export PATH=\$PATH:/usr/local/bin$'
       line: 'export PATH=$PATH:/usr/local/bin'
