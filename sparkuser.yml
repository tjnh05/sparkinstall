---
# Create sparkuser home directory of hdfs
# written by bodhi wang
# bodwang@deloitte.com.cn
# Dec 26, 2017
- hosts: sparkm.deloittecloud.com
  become: yes
  become_user: root

  vars:
     SPARK_HOME=/usr/hdp/current/spark2-client/
     SPARK_PY_NOTEBOOKS=/opt/data/spark-py-notebooks/

  tasks:
   - name: Set environment variable SPARK_MAJOR_VERSION as 2
     lineinfile:
       path: /etc/environment
       regexp: '^export SPARK_MAJOR_VERSION'
       line: 'export SPARK_MAJOR_VERSION=2'
       
   - name: Create HDFS home directory for user sparkuser
     command: "sudo -u hdfs hadoop fs -mkdir /user/sparkuser"
     
   - name: Change owner of HDFS directory /user/sparkuser to sparkuser
     command: "sudo -u hdfs hadoop fs -chown sparkuser /user/sparkuser"

   - name: Create directory downloads
     file:
       path: /root/downloads
       recurse: yes
       owner: root
       group: root
       mode:  0755

   - name: Create symbolic link from source /opt/data/spark-py-notebooks
     command: "ln -s /opt/data/spark-py-notebooks {{SPARK_HOME}}spark-py-notebooks"
     args:
       creates: "{{SPARK_HOME}}spark-py-notebooks" 
       
   - name: Download file VS14MORT.txt.gz if not exists
     get_url:
       dest: /root/downloads/
       url: {{items}}
     with_items:
       - http://tomdrabas.com/data/VS14MORT.txt.gz

   - name: Put local files to HDFS directory /user/sparkuser/
     command: "sudo -u hdfs hadoop fs -put {{item}}"
     with_items:
       - /root/downloads/VS14MORT.txt.gz
       - "{{SPARK_HOME}}data"
       - "{{SPARK_HOME}}examples"
       - "{{SPARK_PY_NOTEBOOKS}}README.md"
       - "{{SPARK_PY_NOTEBOOKS}}nb10-sql-dataframes/kddcup.data_10_percent.gz"
       - "{{SPARK_PY_NOTEBOOKS}}nb3-rdd-sampling/kddcup.data.gz"
       
